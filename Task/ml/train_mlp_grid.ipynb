{
 "cells": [
  {
   "cell_type": "code",
   "id": "104fc549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:06:45.746054Z",
     "start_time": "2024-09-06T12:06:45.740653Z"
    }
   },
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from Preprocessing.feature_extraction import load_eeg_data, compute_band_power, extract_features\n",
    "import warnings\n",
    "mne.set_log_level('error')\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "51333972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:06:45.758360Z",
     "start_time": "2024-09-06T12:06:45.749277Z"
    }
   },
   "source": [
    "def pipeline(base_path):\n",
    "    train_dir = base_path + 'train4ml.csv'\n",
    "    test_dir = base_path + 'test4ml.csv'\n",
    "    val_dir = base_path + 'val4ml.csv'\n",
    "    data_train, label_train = load_eeg_data(train_dir)\n",
    "    data_val, label_val = load_eeg_data(val_dir)   \n",
    "    data_test, label_test = load_eeg_data(test_dir)\n",
    "    \n",
    "    train_X = data_train\n",
    "    train_y = label_train\n",
    "    val_X = data_val\n",
    "    val_y = label_val\n",
    "    test_X = data_test\n",
    "    test_y = label_test\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    val_X = scaler.transform(val_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "    \n",
    "    # Train through GridSearchCV\n",
    "    mlp = MLPClassifier()\n",
    "    param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (30, 30, 30)],  # 은닉층 구조\n",
    "    'activation': ['relu', 'tanh'],  # 활성화 함수\n",
    "    'solver': ['adam', 'sgd'],  # 최적화 알고리즘\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # L2 정규화 파라미터\n",
    "    'learning_rate': ['constant', 'adaptive'],  # 학습률 조정 방식\n",
    "    'max_iter': [200, 300, 500]  # 최대 반복 횟수\n",
    "}\n",
    "\n",
    "    grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(train_X, train_y)  # Fit the model on the training data\n",
    "\n",
    "    # Print the best parameters and the best score from the validation process\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation accuracy: {:.2f}%\".format(grid_search.best_score_ * 100))\n",
    "    \n",
    "    # (Validation) Use the best model to make predictions on the validation set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    val_predictions = best_model.predict(val_X)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    print(\"Validation Accuracy: {:.2f}%\".format(accuracy_score(val_y, val_predictions) * 100))\n",
    "    print(\"Validation ROC-AUC Score: {:.2f}\".format(roc_auc_score(val_y, val_predictions)))\n",
    "    print(\"\\nValidation Classification Report:\")\n",
    "    print(classification_report(val_y, val_predictions))\n",
    "    \n",
    "    # (Test) After validation, use the best model to predict on the test set\n",
    "    test_predictions = best_model.predict(test_X)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(accuracy_score(test_y, test_predictions) * 100))\n",
    "    print(\"Test ROC-AUC Score: {:.2f}\".format(roc_auc_score(test_y, test_predictions)))\n",
    "    print(\"\\nTest Classification Report:\")\n",
    "    print(classification_report(test_y, test_predictions))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f9887fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:53:58.449784Z",
     "start_time": "2024-09-25T07:53:58.445537Z"
    }
   },
   "source": [
    "# Load data\n",
    "base_path_1 = 'your_path'\n",
    "base_path_2 = 'your_path'\n",
    "base_path_3 = 'your_path'\n",
    "base_path_4 = 'your_path'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:54:04.524523Z",
     "start_time": "2024-09-25T07:54:04.522093Z"
    }
   },
   "cell_type": "code",
   "source": "train_mlp_1 = pipeline(base_path_1)",
   "id": "c0e383c2f287122c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "train_mlp_2 = pipeline(base_path_2)",
   "id": "6ff146a2047acf35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_mlp_3 = pipeline(base_path_3)",
   "id": "cebc75bab9c55c65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_mlp_4 = pipeline(base_path_4)",
   "id": "9cc2a1972316184c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
