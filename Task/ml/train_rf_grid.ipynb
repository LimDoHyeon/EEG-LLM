{
 "cells": [
  {
   "cell_type": "code",
   "id": "2af30f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:34:14.564656Z",
     "start_time": "2024-09-06T12:34:14.554722Z"
    }
   },
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from Preprocessing.feature_extraction import load_eeg_data, compute_band_power, extract_features\n",
    "mne.set_log_level('error')"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a175154a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:34:14.577228Z",
     "start_time": "2024-09-06T12:34:14.567150Z"
    }
   },
   "source": [
    "def pipeline(base_path):\n",
    "    train_dir = base_path + 'train4ml.csv'\n",
    "    test_dir = base_path + 'test4ml.csv'\n",
    "    val_dir = base_path + 'val4ml.csv'\n",
    "    data_train, label_train = load_eeg_data(train_dir)\n",
    "    data_val, label_val = load_eeg_data(val_dir)   \n",
    "    data_test, label_test = load_eeg_data(test_dir)\n",
    "    \n",
    "    train_X = data_train\n",
    "    train_y = label_train\n",
    "    val_X = data_val\n",
    "    val_y = label_val\n",
    "    test_X = data_test\n",
    "    test_y = label_test\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    val_X = scaler.transform(val_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    val_X = scaler.transform(val_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "    \n",
    "    # Train through GridSearchCV\n",
    "    rf = RandomForestClassifier()\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],  # 트리의 개수\n",
    "        'max_depth': [10, 20, None],  # 트리의 최대 깊이\n",
    "        'min_samples_split': [2, 5, 10],  # 분할을 위한 최소 샘플 수\n",
    "        'min_samples_leaf': [1, 2, 4],  # 리프 노드의 최소 샘플 수\n",
    "        'max_features': ['sqrt', 'log2', None]  # 고려할 최대 피처 수\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(train_X, train_y)  # Fit the model on the training data\n",
    "\n",
    "    # Print the best parameters and the best score from the validation process\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation accuracy: {:.2f}%\".format(grid_search.best_score_ * 100))\n",
    "    \n",
    "    # (Validation) Use the best model to make predictions on the validation set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    val_predictions = best_model.predict(val_X)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    print(\"Validation Accuracy: {:.2f}%\".format(accuracy_score(val_y, val_predictions) * 100))\n",
    "    print(\"Validation ROC-AUC Score: {:.2f}\".format(roc_auc_score(val_y, val_predictions)))\n",
    "    print(\"\\nValidation Classification Report:\")\n",
    "    print(classification_report(val_y, val_predictions))\n",
    "    \n",
    "    # (Test) After validation, use the best model to predict on the test set\n",
    "    test_predictions = best_model.predict(test_X)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(accuracy_score(test_y, test_predictions) * 100))\n",
    "    print(\"Test ROC-AUC Score: {:.2f}\".format(roc_auc_score(test_y, test_predictions)))\n",
    "    print(\"\\nTest Classification Report:\")\n",
    "    print(classification_report(test_y, test_predictions))"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "2ad3f3f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:34:14.581406Z",
     "start_time": "2024-09-06T12:34:14.578395Z"
    }
   },
   "source": [
    "# Load data\n",
    "base_path_1 = 'your_path'\n",
    "base_path_2 = 'your_path'\n",
    "base_path_3 = 'your_path'\n",
    "base_path_4 = 'your_path'\n",
    "window_size = 1000"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_rf_1 = pipeline(base_path_1)",
   "id": "e38a4fe3c669c417"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_rf_2 = pipeline(base_path_2)",
   "id": "c7ee51cb2d1814e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_rf_3 = pipeline(base_path_3)",
   "id": "56c70292e377b84b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_rf_4 = pipeline(base_path_4)",
   "id": "64469977f7241288"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
